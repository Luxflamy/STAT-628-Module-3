{
 "cells": [
  {
   "cell_type": "code",
   "id": "3bf4661e54d440e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:15:54.161125Z",
     "start_time": "2025-04-17T19:15:54.154715Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from joblib import dump\n",
    "\n",
    "flight_data_path = './cleaned_data/'\n",
    "weather_data_path = './cleaned_weather_data/'\n",
    "top_airports_file = './top_100_airports.csv'\n",
    "output_dir = './cancelled_prob_lr_models/'\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'metrics'), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_dir, 'plots'), exist_ok=True)\n",
    "\n",
    "print(\"Starting flight cancellation prediction models with red-eye flight detection (Logistic Regression)...\")\n",
    "print(f\"Flight data directory: {flight_data_path}\")\n",
    "print(f\"Weather data directory: {weather_data_path}\")\n",
    "print(f\"Top airports file: {top_airports_file}\")\n",
    "print(f\"Model output directory: {output_dir}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting flight cancellation prediction models with red-eye flight detection (Logistic Regression)...\n",
      "Flight data directory: ./cleaned_data/\n",
      "Weather data directory: ./cleaned_weather_data/\n",
      "Top airports file: ./top_100_airports.csv\n",
      "Model output directory: ./cancelled_prob_lr_models/\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "a19886992a6ad2de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:15:54.175132Z",
     "start_time": "2025-04-17T19:15:54.168131Z"
    }
   },
   "source": [
    "try:\n",
    "    top_airports = pd.read_csv(top_airports_file, low_memory=False)\n",
    "    \n",
    "    top_airports = top_airports.head(30)\n",
    "    \n",
    "    top_airport_codes = set(top_airports['ORIGIN_IATA'].str.strip().tolist())\n",
    "    \n",
    "    print(f\"Loaded top 30 airports: {', '.join(sorted(top_airport_codes))}\")\n",
    "    print(f\"Busiest airport: {top_airports.iloc[0]['ORIGIN_IATA']} with {top_airports.iloc[0]['Times']} flights\")\n",
    "    print(f\"30th busiest airport: {top_airports.iloc[29]['ORIGIN_IATA']} with {top_airports.iloc[29]['Times']} flights\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading top airports file: {e}\")\n",
    "    top_airport_codes = None\n",
    "    print(\"Will process all airports (top airports file not available)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded top 30 airports: ATL, AUS, BNA, BOS, BWI, CLT, DCA, DEN, DFW, DTW, EWR, FLL, IAD, IAH, JFK, LAS, LAX, LGA, MCO, MDW, MIA, MSP, ORD, PHL, PHX, SAN, SEA, SFO, SLC, TPA\n",
      "Busiest airport: ATL with 457121 flights\n",
      "30th busiest airport: TPA with 97235 flights\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "8b25cd6abc0f8841",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:15:54.200914Z",
     "start_time": "2025-04-17T19:15:54.191905Z"
    }
   },
   "source": [
    "\n",
    "def load_weather_data():\n",
    "    print(\"\\nLoading weather data for May 2021-2024...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    all_files = glob.glob(os.path.join(weather_data_path, \"*.csv\"))\n",
    "    print(f\"Found {len(all_files)} total weather data files\")\n",
    "    weather_dict = {}\n",
    "    count = 0\n",
    "    matching_count = 0\n",
    "    \n",
    "    target_years = ['2021', '2022', '2023', '2024']\n",
    "    target_month = 'May'\n",
    "    \n",
    "    for file in all_files:\n",
    "        try:\n",
    "            filename = os.path.basename(file)\n",
    "            parts = filename.split('.')[0].split('_')\n",
    "            \n",
    "            if len(parts) >= 3:\n",
    "                iata = parts[0]\n",
    "                year = parts[1]\n",
    "                month = parts[2]\n",
    "                \n",
    "                # Only load weather data for May 2021-2024 and top airports\n",
    "                if (year in target_years and \n",
    "                    month == target_month and\n",
    "                    (top_airport_codes is None or iata in top_airport_codes)):\n",
    "                    \n",
    "                    key = f\"{iata}_{year}_{month}\"\n",
    "                    \n",
    "                    weather_dict[key] = pd.read_csv(file, low_memory=False)\n",
    "                    matching_count += 1\n",
    "                \n",
    "                count += 1\n",
    "                    \n",
    "                if count % 100 == 0:\n",
    "                    print(f\"Processed {count} weather files, loaded {matching_count} matching files\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading weather file {file}: {e}\")\n",
    "    \n",
    "    print(f\"Loaded {matching_count} weather files for May 2021-2024 out of {count} processed files\")\n",
    "    print(f\"Loading weather data took: {time.time() - start_time:.2f} seconds\")\n",
    "    return weather_dict\n",
    "\n",
    "# Get specific May files from the cleaned_data directory based on the file list you shared\n",
    "def get_may_files():\n",
    "    may_files = [\n",
    "        os.path.join(flight_data_path, \"May2021.csv\"),\n",
    "        os.path.join(flight_data_path, \"May2022.csv\"),\n",
    "        os.path.join(flight_data_path, \"May2023.csv\"),\n",
    "        os.path.join(flight_data_path, \"May2024.csv\")\n",
    "    ]\n",
    "    \n",
    "    existing_files = []\n",
    "    for file_path in may_files:\n",
    "        if os.path.exists(file_path):\n",
    "            existing_files.append(file_path)\n",
    "        else:\n",
    "            print(f\"Warning: File {file_path} not found\")\n",
    "    \n",
    "    return existing_files"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "b7b9c1b3acf609f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:15:54.419026Z",
     "start_time": "2025-04-17T19:15:54.218992Z"
    }
   },
   "source": [
    "# Get the May 2021-2024 flight data files\n",
    "flight_files = get_may_files()\n",
    "print(f\"\\nFound {len(flight_files)} May files to process:\")\n",
    "for f in flight_files:\n",
    "    print(f\"  - {os.path.basename(f)}\")\n",
    "\n",
    "if not flight_files:\n",
    "    print(\"No May 2021-2024 files were found. Please check file paths.\")\n",
    "    exit(1)\n",
    "\n",
    "weather_dict = load_weather_data()\n",
    "\n",
    "# Function to extract year from filename (for logging purposes only)\n",
    "def extract_year_from_filename(filename):\n",
    "    base_name = os.path.basename(filename)\n",
    "    year_str = base_name.replace('May', '').split('.')[0]\n",
    "    return int(year_str)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Found 4 May files to process:\n",
      "  - May2021.csv\n",
      "  - May2022.csv\n",
      "  - May2023.csv\n",
      "  - May2024.csv\n",
      "\n",
      "Loading weather data for May 2021-2024...\n",
      "Found 3550 total weather data files\n",
      "Processed 100 weather files, loaded 0 matching files\n",
      "Processed 200 weather files, loaded 0 matching files\n",
      "Processed 300 weather files, loaded 4 matching files\n",
      "Processed 400 weather files, loaded 8 matching files\n",
      "Processed 500 weather files, loaded 8 matching files\n",
      "Processed 600 weather files, loaded 12 matching files\n",
      "Processed 700 weather files, loaded 12 matching files\n",
      "Processed 800 weather files, loaded 12 matching files\n",
      "Processed 900 weather files, loaded 16 matching files\n",
      "Processed 1000 weather files, loaded 16 matching files\n",
      "Processed 1100 weather files, loaded 20 matching files\n",
      "Processed 1200 weather files, loaded 24 matching files\n",
      "Processed 1300 weather files, loaded 28 matching files\n",
      "Processed 1400 weather files, loaded 28 matching files\n",
      "Processed 1500 weather files, loaded 28 matching files\n",
      "Processed 1600 weather files, loaded 28 matching files\n",
      "Processed 1700 weather files, loaded 32 matching files\n",
      "Processed 1800 weather files, loaded 32 matching files\n",
      "Processed 1900 weather files, loaded 35 matching files\n",
      "Processed 2000 weather files, loaded 40 matching files\n",
      "Processed 2100 weather files, loaded 40 matching files\n",
      "Processed 2200 weather files, loaded 48 matching files\n",
      "Processed 2300 weather files, loaded 52 matching files\n",
      "Processed 2400 weather files, loaded 52 matching files\n",
      "Processed 2500 weather files, loaded 56 matching files\n",
      "Processed 2600 weather files, loaded 60 matching files\n",
      "Processed 2700 weather files, loaded 60 matching files\n",
      "Processed 2800 weather files, loaded 64 matching files\n",
      "Processed 2900 weather files, loaded 64 matching files\n",
      "Processed 3000 weather files, loaded 68 matching files\n",
      "Processed 3100 weather files, loaded 71 matching files\n",
      "Processed 3200 weather files, loaded 76 matching files\n",
      "Processed 3300 weather files, loaded 80 matching files\n",
      "Processed 3400 weather files, loaded 84 matching files\n",
      "Processed 3500 weather files, loaded 84 matching files\n",
      "Loaded 84 weather files for May 2021-2024 out of 3550 processed files\n",
      "Loading weather data took: 0.19 seconds\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "2241a562a8dca6e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:15:54.444213Z",
     "start_time": "2025-04-17T19:15:54.435213Z"
    }
   },
   "source": [
    "def create_redeye_indicator(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    df['IS_REDEYE'] = 0\n",
    "    \n",
    "    time_columns = []\n",
    "    \n",
    "    if 'SCH_DEP_TIME' in df.columns:\n",
    "        time_columns.append('SCH_DEP_TIME')\n",
    "    \n",
    "    if 'SCH_ARR_TIME' in df.columns:\n",
    "        time_columns.append('SCH_ARR_TIME')\n",
    "    \n",
    "    for col in time_columns:\n",
    "        if df[col].dtype != 'float64':\n",
    "            try:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            except:\n",
    "                print(f\"Warning: Could not convert {col} to numeric\")\n",
    "    \n",
    "    if 'SCH_DEP_TIME' in time_columns:\n",
    "        redeye_departure = (df['SCH_DEP_TIME'] >= 0) & (df['SCH_DEP_TIME'] < 600)\n",
    "        df.loc[redeye_departure, 'IS_REDEYE'] = 1\n",
    "        \n",
    "        dep_redeye_count = redeye_departure.sum()\n",
    "        print(f\"Identified {dep_redeye_count} red-eye flights based on departure time (0-6 AM)\")\n",
    "    \n",
    "    if 'SCH_ARR_TIME' in time_columns:\n",
    "        redeye_arrival = (df['SCH_ARR_TIME'] >= 0) & (df['SCH_ARR_TIME'] < 600)\n",
    "        df.loc[redeye_arrival, 'IS_REDEYE'] = 1\n",
    "        \n",
    "        arr_redeye_count = redeye_arrival.sum()\n",
    "        print(f\"Identified {arr_redeye_count} red-eye flights based on arrival time (0-6 AM)\")\n",
    "    \n",
    "    redeye_count = df['IS_REDEYE'].sum()\n",
    "    total_count = len(df)\n",
    "    print(f\"Total identified red-eye flights: {redeye_count} out of {total_count} total flights ({redeye_count/total_count*100:.2f}%)\")\n",
    "    \n",
    "    if 'SCH_DEP_TIME' in time_columns:\n",
    "        df['DEP_TIME_OF_DAY'] = pd.cut(\n",
    "            df['SCH_DEP_TIME'], \n",
    "            bins=[0, 600, 1200, 1800, 2400],\n",
    "            labels=['Early Morning (0-6)', 'Morning (6-12)', 'Afternoon (12-18)', 'Evening (18-24)'],\n",
    "            include_lowest=True\n",
    "        )\n",
    "        \n",
    "        time_dist = df['DEP_TIME_OF_DAY'].value_counts()\n",
    "        print(\"\\nDistribution of flights by departure time of day:\")\n",
    "        for time_cat, count in time_dist.items():\n",
    "            print(f\"  - {time_cat}: {count} flights ({count/total_count*100:.2f}%)\")\n",
    "    \n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "5d2344ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:15:54.490504Z",
     "start_time": "2025-04-17T19:15:54.460763Z"
    }
   },
   "source": [
    "def train_model_for_file(file_path, file_index, total_files):\n",
    "    file_name = os.path.basename(file_path)\n",
    "    model_name = os.path.splitext(file_name)[0]\n",
    "    file_year = extract_year_from_filename(file_name)  \n",
    "    \n",
    "    print(f\"\\nProcessing file {file_index+1}/{total_files}: {file_name} (May {file_year})\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        flight_df = pd.read_csv(file_path, low_memory=False)\n",
    "        original_size = len(flight_df)\n",
    "        \n",
    "        if 'MONTH' in flight_df.columns:\n",
    "            month_counts = flight_df['MONTH'].value_counts()\n",
    "            print(f\"Months found in data: {dict(month_counts)}\")\n",
    "            \n",
    "            if 5 in month_counts:\n",
    "                flight_df = flight_df[flight_df['MONTH'] == 5]\n",
    "                print(f\"Filtered to only May data: {len(flight_df)} rows\")\n",
    "            else:\n",
    "                print(f\"Warning: No May data found in file, but proceeding anyway as this should be May data based on filename\")\n",
    "        \n",
    "        if top_airport_codes is not None:\n",
    "            flight_df = flight_df[\n",
    "                flight_df['ORIGIN_IATA'].str.strip().isin(top_airport_codes) & \n",
    "                flight_df['DEST_IATA'].str.strip().isin(top_airport_codes)\n",
    "            ]\n",
    "            \n",
    "            filtered_size = len(flight_df)\n",
    "            print(f\"Filtered from {original_size} to {filtered_size} rows for top 30 airports\")\n",
    "            \n",
    "            if filtered_size == 0:\n",
    "                print(f\"No data remaining after filtering for top 30 airports. Skipping file.\")\n",
    "                return {\n",
    "                    'file_name': file_name,\n",
    "                    'status': 'skipped',\n",
    "                    'reason': 'empty_after_filtering'\n",
    "                }\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading flight data file {file_path}: {e}\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'error',\n",
    "            'reason': str(e)\n",
    "        }\n",
    "    \n",
    "    print(\"Creating red-eye flight indicator...\")\n",
    "    flight_df = create_redeye_indicator(flight_df)\n",
    "    \n",
    "    print(f\"Final dataset shape: {flight_df.shape}\")\n",
    "    \n",
    "    print(\"Preprocessing data...\")\n",
    "    \n",
    "    if 'CANCELLED' in flight_df.columns:\n",
    "        flight_df['IS_CANCELLED'] = flight_df['CANCELLED'].astype(int)\n",
    "    else:\n",
    "        print(\"No CANCELLED column found. Skipping file.\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'skipped',\n",
    "            'reason': 'no_cancelled_column'\n",
    "        }\n",
    "    \n",
    "    if 'WEEK' not in flight_df.columns:\n",
    "        if 'DAY' in flight_df.columns and 'MONTH' in flight_df.columns and 'YEAR' in flight_df.columns:\n",
    "            if 'DATE' not in flight_df.columns:\n",
    "                flight_df['DATE'] = pd.to_datetime(flight_df[['YEAR', 'MONTH', 'DAY']])\n",
    "            flight_df['WEEK'] = flight_df['DATE'].dt.dayofweek\n",
    "        else:\n",
    "            print(\"Cannot create WEEK column. Required columns missing. Skipping file.\")\n",
    "            return {\n",
    "                'file_name': file_name,\n",
    "                'status': 'skipped',\n",
    "                'reason': 'missing_columns_for_week'\n",
    "            }\n",
    "    \n",
    "    cancelled_count = flight_df['IS_CANCELLED'].sum()\n",
    "    total_count = len(flight_df)\n",
    "    \n",
    "    if cancelled_count == 0:\n",
    "        print(f\"No cancelled flights in this dataset. Skipping file.\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'skipped',\n",
    "            'reason': 'no_cancelled_flights'\n",
    "        }\n",
    "    \n",
    "    cancellation_rate = cancelled_count / total_count * 100\n",
    "    print(f\"Overall cancellation rate: {cancelled_count}/{total_count} ({cancellation_rate:.2f}%)\")\n",
    "    \n",
    "    redeye_df = flight_df[flight_df['IS_REDEYE'] == 1]\n",
    "    non_redeye_df = flight_df[flight_df['IS_REDEYE'] == 0]\n",
    "    \n",
    "    if len(redeye_df) > 0:\n",
    "        redeye_cancel_rate = redeye_df['IS_CANCELLED'].mean() * 100\n",
    "        print(f\"Red-eye flights cancellation rate: {redeye_cancel_rate:.2f}%\")\n",
    "    \n",
    "    if len(non_redeye_df) > 0:\n",
    "        non_redeye_cancel_rate = non_redeye_df['IS_CANCELLED'].mean() * 100\n",
    "        print(f\"Non-red-eye flights cancellation rate: {non_redeye_cancel_rate:.2f}%\")\n",
    "    \n",
    "    print(\"Matching weather data with flights...\")\n",
    "    \n",
    "    if 'YEAR' in flight_df.columns and 'MONTH' in flight_df.columns and 'DAY' in flight_df.columns:\n",
    "        flight_df['WEATHER_KEY'] = flight_df['ORIGIN_IATA'] + '_' + flight_df['YEAR'].astype(str) + '_' + flight_df['MONTH'].astype(str).str.zfill(2)\n",
    "        if 'FLIGHT_DATE' not in flight_df.columns:\n",
    "            flight_df['FLIGHT_DATE'] = pd.to_datetime(flight_df[['YEAR', 'MONTH', 'DAY']])\n",
    "    \n",
    "    flight_df['EXTREME_WEATHER'] = 0  \n",
    "    flight_df['PRCP'] = 0.0\n",
    "    \n",
    "    matched_count = 0\n",
    "    batch_size = 5000\n",
    "    \n",
    "    for start_idx in range(0, len(flight_df), batch_size):\n",
    "        end_idx = min(start_idx + batch_size, len(flight_df))\n",
    "        batch = flight_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        for idx, row in batch.iterrows():\n",
    "            try:\n",
    "                weather_key = row['WEATHER_KEY']\n",
    "                flight_date = row['FLIGHT_DATE']\n",
    "                \n",
    "                if weather_key in weather_dict:\n",
    "                    weather_data = weather_dict[weather_key]\n",
    "                    if not pd.api.types.is_datetime64_any_dtype(weather_data['DATE']):\n",
    "                        weather_data['DATE'] = pd.to_datetime(weather_data['DATE'])\n",
    "                    \n",
    "                    matching_weather = weather_data[weather_data['DATE'] == flight_date]\n",
    "                    \n",
    "                    if not matching_weather.empty:\n",
    "                        if 'EXTREME_WEATHER' in matching_weather.columns:\n",
    "                            flight_df.at[idx, 'EXTREME_WEATHER'] = matching_weather['EXTREME_WEATHER'].iloc[0]\n",
    "                        if 'PRCP' in matching_weather.columns:\n",
    "                            flight_df.at[idx, 'PRCP'] = matching_weather['PRCP'].iloc[0]\n",
    "                        matched_count += 1\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    \n",
    "    print(f\"Matched weather data for {matched_count} flights ({matched_count/len(flight_df)*100:.2f}%)\")\n",
    "    \n",
    "    print(\"Selecting features...\")\n",
    "    \n",
    "    cat_features = [\"YEAR\", 'WEEK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA','EXTREME_WEATHER',  'IS_REDEYE', 'IS_WEEKEND', 'IS_MORNING_PEAK', 'IS_EVENING_PEAK']\n",
    "    num_features = ['DISTANCE','PRCP']\n",
    "    \n",
    "    \n",
    "    cat_features = [f for f in cat_features if f in flight_df.columns]\n",
    "    num_features = [f for f in num_features if f in flight_df.columns]\n",
    "    \n",
    "    if not cat_features or not num_features:\n",
    "        print(\"Missing required features. Skipping file.\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'skipped',\n",
    "            'reason': 'missing_required_features'\n",
    "        }\n",
    "    \n",
    "    print(f\"Using categorical features: {cat_features}\")\n",
    "    print(f\"Using numerical features: {num_features}\")\n",
    "    \n",
    "    X = flight_df[cat_features + num_features].copy()\n",
    "    y = flight_df['IS_CANCELLED'].copy()\n",
    "    \n",
    "    for col in cat_features:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col].fillna('unknown', inplace=True)\n",
    "    for col in num_features:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            X[col].fillna(X[col].median(), inplace=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2025, stratify=y)\n",
    "    print(f\"Training set size: {X_train.shape}\")\n",
    "    print(f\"Test set size: {X_test.shape}\")\n",
    "    \n",
    "    print(\"Training logistic regression model...\")\n",
    "    model_start_time = time.time()\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_features),\n",
    "            ('cat', categorical_transformer, cat_features)\n",
    "        ])\n",
    "\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(max_iter=500, class_weight='balanced', C=1.0))\n",
    "    ])\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    final_model = model\n",
    "    \n",
    "    y_pred = final_model.predict(X_test)\n",
    "    y_prob = final_model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    try:\n",
    "        feature_names = final_model.named_steps['preprocessor'].get_feature_names_out()\n",
    "    except:\n",
    "        feature_names = []\n",
    "        feature_names.extend(num_features)  \n",
    "        for i, feature in enumerate(cat_features):\n",
    "            encoder = final_model.named_steps['preprocessor'].transformers_[1][1].named_steps['onehot']\n",
    "            categories = encoder.categories_[i]\n",
    "            feature_names.extend([f\"{feature}_{cat}\" for cat in categories])\n",
    "    \n",
    "    coefficients = final_model.named_steps['classifier'].coef_[0]\n",
    "    \n",
    "    model_training_time = time.time() - model_start_time\n",
    "    print(f\"Model training took: {model_training_time:.2f} seconds\")\n",
    "    \n",
    "    print(\"Evaluating model...\")\n",
    "    \n",
    "    if not isinstance(y_pred, np.ndarray) or len(y_pred) == 0:\n",
    "        print(\"No predictions available. Skipping evaluation.\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'error',\n",
    "            'reason': 'prediction_failed'\n",
    "        }\n",
    "    \n",
    "    try:\n",
    "        accuracy = (y_pred == y_test).mean() * 100\n",
    "        roc_auc = roc_auc_score(y_test, y_prob)\n",
    "        \n",
    "        report = classification_report(y_test, y_pred, output_dict=True)\n",
    "        \n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "        if len(feature_names) == len(coefficients):\n",
    "            feature_importance = pd.DataFrame({\n",
    "                'Feature': feature_names,\n",
    "                'Coefficient': coefficients\n",
    "            })\n",
    "            feature_importance['Abs_Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "            feature_importance = feature_importance.sort_values('Abs_Coefficient', ascending=False)\n",
    "            \n",
    "            print(\"\\nTop 10 most important features:\")\n",
    "            print(feature_importance.head(10))\n",
    "            \n",
    "            redeye_importance = feature_importance[feature_importance['Feature'] == 'IS_REDEYE']\n",
    "            if not redeye_importance.empty:\n",
    "                coef = redeye_importance.iloc[0]['Coefficient']\n",
    "                effect = \"increases\" if coef > 0 else \"decreases\"\n",
    "                print(f\"\\nRed-eye flight effect: Being a red-eye flight {effect} cancellation risk\")\n",
    "                print(f\"IS_REDEYE coefficient: {coef:.4f}\")\n",
    "                print(f\"IS_REDEYE importance rank: {feature_importance[feature_importance['Feature'] == 'IS_REDEYE'].index[0] + 1} out of {len(feature_importance)}\")\n",
    "            \n",
    "            feature_importance.to_csv(os.path.join(output_dir, 'metrics', f\"{model_name}_feature_importance.csv\"), index=False)\n",
    "            \n",
    "            # Plot feature importance\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            top_features = feature_importance.head(15)  # Top 15 features\n",
    "            sns.barplot(x='Coefficient', y='Feature', data=top_features)\n",
    "            plt.axvline(x=0, color='gray', linestyle='--')\n",
    "            plt.title(f'Top 15 Feature Coefficients for {model_name}')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'plots', f\"{model_name}_feature_importance.png\"))\n",
    "            plt.close()\n",
    "        else:\n",
    "            print(f\"Feature names ({len(feature_names)}) and coefficients ({len(coefficients)}) length mismatch\")\n",
    "        \n",
    "        # Plot ROC curve\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title(f'ROC Curve for {model_name} (Logistic Regression)')\n",
    "        plt.legend()\n",
    "        plt.savefig(os.path.join(output_dir, 'plots', f\"{model_name}_roc_curve.png\"))\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['Not Cancelled', 'Cancelled'],\n",
    "                   yticklabels=['Not Cancelled', 'Cancelled'])\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.title(f'Confusion Matrix for {model_name}')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, 'plots', f\"{model_name}_confusion_matrix.png\"))\n",
    "        plt.close()\n",
    "        \n",
    "        # Plot cancellation rate comparison\n",
    "        if len(redeye_df) > 0 and len(non_redeye_df) > 0:\n",
    "            plt.figure(figsize=(16, 10))\n",
    "            categories = ['Non-Red-Eye', 'Red-Eye']\n",
    "            rates = [non_redeye_cancel_rate, redeye_cancel_rate]\n",
    "            counts = [len(non_redeye_df), len(redeye_df)]\n",
    "            \n",
    "            bars = plt.bar(categories, rates, color=['skyblue', 'navy'])\n",
    "            \n",
    "            for i, (bar, rate, count) in enumerate(zip(bars, rates, counts)):\n",
    "                plt.text(i, rate + 0.5, f\"{rate:.2f}%\\n({count} flights)\", \n",
    "                         ha='center', va='bottom')\n",
    "            \n",
    "            plt.ylabel('Cancellation Rate (%)')\n",
    "            plt.title(f'Cancellation Rate Comparison: Red-Eye vs. Non-Red-Eye Flights ({model_name})')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'plots', f\"{model_name}_redeye_comparison.png\"))\n",
    "            plt.close()\n",
    "        \n",
    "        model_path = os.path.join(output_dir, f\"{model_name}_model.joblib\")\n",
    "        dump(final_model, model_path)\n",
    "        print(f\"Model saved to {model_path}\")\n",
    "        \n",
    "        # Save metrics summary\n",
    "        metrics = {\n",
    "            'file_name': file_name,\n",
    "            'model_name': model_name,\n",
    "            'file_year': file_year,  \n",
    "            'accuracy': accuracy,\n",
    "            'roc_auc': roc_auc,\n",
    "            'precision': report['1']['precision'],\n",
    "            'recall': report['1']['recall'],\n",
    "            'f1_score': report['1']['f1-score'],\n",
    "            'cancellation_rate': cancellation_rate,\n",
    "            'training_time': model_training_time,\n",
    "            'training_size': len(X_train),\n",
    "            'test_size': len(X_test),\n",
    "            'status': 'success'\n",
    "        }\n",
    "        \n",
    "        metrics['redeye_count'] = len(redeye_df)\n",
    "        metrics['redeye_percentage'] = len(redeye_df) / len(flight_df) * 100\n",
    "        metrics['redeye_cancel_rate'] = redeye_cancel_rate if len(redeye_df) > 0 else None\n",
    "        metrics['non_redeye_cancel_rate'] = non_redeye_cancel_rate if len(non_redeye_df) > 0 else None\n",
    "        \n",
    "        if not redeye_importance.empty:\n",
    "            metrics['redeye_coefficient'] = coef\n",
    "            metrics['redeye_rank'] = feature_importance[feature_importance['Feature'] == 'IS_REDEYE'].index[0] + 1\n",
    "        \n",
    "        # Save confusion matrix values\n",
    "        metrics['true_negative'] = cm[0, 0]\n",
    "        metrics['false_positive'] = cm[0, 1]\n",
    "        metrics['false_negative'] = cm[1, 0]\n",
    "        metrics['true_positive'] = cm[1, 1]\n",
    "        \n",
    "        # Save top 5 most important features\n",
    "        if len(feature_names) == len(coefficients):\n",
    "            for i in range(min(5, len(feature_importance))):\n",
    "                feat = feature_importance.iloc[i]\n",
    "                metrics[f'top_feature_{i+1}'] = feat['Feature']\n",
    "                metrics[f'top_feature_{i+1}_coef'] = feat['Coefficient']\n",
    "        \n",
    "        print(f\"Processing of {file_name} completed in {time.time() - start_time:.2f} seconds\")\n",
    "        return metrics\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in evaluation: {e}\")\n",
    "        return {\n",
    "            'file_name': file_name,\n",
    "            'status': 'error',\n",
    "            'reason': str(e)\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "3ce6cb06",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-17T19:16:31.884939Z",
     "start_time": "2025-04-17T19:15:54.507060Z"
    }
   },
   "source": [
    "# Sequential processing of the May files\n",
    "results = []\n",
    "for i, file_path in enumerate(flight_files):\n",
    "    result = train_model_for_file(file_path, i, len(flight_files))\n",
    "    results.append(result)\n",
    "\n",
    "# Summarize results\n",
    "print(\"\\nSummary of logistic regression model training:\")\n",
    "success_count = sum(1 for r in results if r.get('status') == 'success')\n",
    "error_count = sum(1 for r in results if r.get('status') == 'error')\n",
    "skipped_count = sum(1 for r in results if r.get('status') == 'skipped')\n",
    "\n",
    "print(f\"Successfully trained models: {success_count}/{len(results)}\")\n",
    "print(f\"Failed models: {error_count}/{len(results)}\")\n",
    "print(f\"Skipped files: {skipped_count}/{len(results)}\")\n",
    "\n",
    "# Create a summary DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv(os.path.join(output_dir, 'cancelled_prob_lr_summary.csv'), index=False)\n",
    "\n",
    "# Calculate average metrics for successful models\n",
    "if success_count > 0:\n",
    "    successful_results = [r for r in results if r.get('status') == 'success']\n",
    "    avg_accuracy = sum(r.get('accuracy', 0) for r in successful_results) / success_count\n",
    "    avg_roc_auc = sum(r.get('roc_auc', 0) for r in successful_results) / success_count\n",
    "    avg_precision = sum(r.get('precision', 0) for r in successful_results) / success_count\n",
    "    avg_recall = sum(r.get('recall', 0) for r in successful_results) / success_count\n",
    "    \n",
    "    print(\"\\nAverage metrics across all successful models:\")\n",
    "    print(f\"Accuracy: {avg_accuracy:.2f}%\")\n",
    "    print(f\"ROC AUC: {avg_roc_auc:.4f}\")\n",
    "    print(f\"Precision: {avg_precision:.4f}\")\n",
    "    print(f\"Recall: {avg_recall:.4f}\")\n",
    "    \n",
    "    # For successful models, identify most common important features\n",
    "    feature_counts = {}\n",
    "    for result in successful_results:\n",
    "        for i in range(1, 6):  # Top 5 features\n",
    "            feature_key = f'top_feature_{i}'\n",
    "            if feature_key in result:\n",
    "                feature = result[feature_key]\n",
    "                if feature in feature_counts:\n",
    "                    feature_counts[feature] += 1\n",
    "                else:\n",
    "                    feature_counts[feature] = 1\n",
    "    \n",
    "    if feature_counts:\n",
    "        print(\"\\nMost common important features across all models:\")\n",
    "        sorted_features = sorted(feature_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "        for feature, count in sorted_features[:10]:  # Top 10 most common\n",
    "            print(f\"{feature}: Appears in {count} models ({count/success_count*100:.1f}%)\")\n",
    "    \n",
    "    if all('redeye_coefficient' in r for r in successful_results):\n",
    "        coefficients = [r['redeye_coefficient'] for r in successful_results]\n",
    "        avg_coef = sum(coefficients) / len(coefficients)\n",
    "        effect = \"increases\" if avg_coef > 0 else \"decreases\"\n",
    "        \n",
    "        print(f\"\\nRed-eye flight effect (across all models): Being a red-eye flight generally {effect} cancellation risk\")\n",
    "        print(f\"Average IS_REDEYE coefficient: {avg_coef:.4f}\")\n",
    "        \n",
    "        positive_count = sum(1 for c in coefficients if c > 0)\n",
    "        negative_count = sum(1 for c in coefficients if c < 0)\n",
    "        print(f\"Models where red-eye increases cancellation risk: {positive_count}/{len(coefficients)}\")\n",
    "        print(f\"Models where red-eye decreases cancellation risk: {negative_count}/{len(coefficients)}\")\n",
    "    \n",
    "    # Plot combined red-eye vs non-red-eye cancellation rate comparison\n",
    "    if all('redeye_cancel_rate' in r and 'non_redeye_cancel_rate' in r for r in successful_results):\n",
    "        redeye_rates = [r['redeye_cancel_rate'] for r in successful_results if r['redeye_cancel_rate'] is not None]\n",
    "        non_redeye_rates = [r['non_redeye_cancel_rate'] for r in successful_results if r['non_redeye_cancel_rate'] is not None]\n",
    "        \n",
    "        if redeye_rates and non_redeye_rates:\n",
    "            avg_redeye_rate = sum(redeye_rates) / len(redeye_rates)\n",
    "            avg_non_redeye_rate = sum(non_redeye_rates) / len(non_redeye_rates)\n",
    "            \n",
    "            redeye_counts = [r.get('redeye_count', 0) for r in successful_results]\n",
    "            total_redeye = sum(redeye_counts)\n",
    "            total_non_redeye = sum(r.get('training_size', 0) + r.get('test_size', 0) for r in successful_results) - total_redeye\n",
    "            \n",
    "            plt.figure(figsize=(16, 10))\n",
    "            categories = ['Non-Red-Eye', 'Red-Eye']\n",
    "            rates = [avg_non_redeye_rate, avg_redeye_rate]\n",
    "            \n",
    "            bars = plt.bar(categories, rates, color=['skyblue', 'navy'])\n",
    "            \n",
    "            for i, (bar, rate, count) in enumerate(zip(bars, rates, [total_non_redeye, total_redeye])):\n",
    "                plt.text(i, rate + 0.5, f\"{rate:.2f}%\\n({count} flights)\", \n",
    "                         ha='center', va='bottom')\n",
    "            \n",
    "            plt.ylabel('Average Cancellation Rate (%)')\n",
    "            plt.title('Average Cancellation Rate Comparison: Red-Eye vs. Non-Red-Eye Flights')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(output_dir, 'plots', 'average_redeye_comparison.png'))\n",
    "            plt.close()\n",
    "            print(\"\\nAverage red-eye vs non-red-eye cancellation rate comparison saved to average_redeye_comparison.png\")\n",
    "\n",
    "print(\"\\nLogistic regression model training with red-eye flight detection complete!\")\n",
    "print(f\"Full summary saved to {os.path.join(output_dir, 'cancelled_prob_lr_summary.csv')}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file 1/4: May2021.csv (May 2021)\n",
      "Months found in data: {5: 520059}\n",
      "Filtered to only May data: 520059 rows\n",
      "Filtered from 520059 to 171867 rows for top 30 airports\n",
      "Creating red-eye flight indicator...\n",
      "Identified 2861 red-eye flights based on departure time (0-6 AM)\n",
      "Identified 4657 red-eye flights based on arrival time (0-6 AM)\n",
      "Total identified red-eye flights: 7202 out of 171867 total flights (4.19%)\n",
      "\n",
      "Distribution of flights by departure time of day:\n",
      "  - Morning (6-12): 67434 flights (39.24%)\n",
      "  - Afternoon (12-18): 61417 flights (35.74%)\n",
      "  - Evening (18-24): 36112 flights (21.01%)\n",
      "  - Early Morning (0-6): 6904 flights (4.02%)\n",
      "Final dataset shape: (171867, 53)\n",
      "Preprocessing data...\n",
      "Overall cancellation rate: 485/171867 (0.28%)\n",
      "Red-eye flights cancellation rate: 0.22%\n",
      "Non-red-eye flights cancellation rate: 0.28%\n",
      "Matching weather data with flights...\n",
      "Matched weather data for 0 flights (0.00%)\n",
      "Selecting features...\n",
      "Using categorical features: ['YEAR', 'WEEK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'EXTREME_WEATHER', 'IS_REDEYE']\n",
      "Using numerical features: ['DISTANCE', 'PRCP']\n",
      "Training set size: (154680, 9)\n",
      "Test set size: (17187, 9)\n",
      "Training logistic regression model...\n",
      "Model training took: 0.87 seconds\n",
      "Evaluating model...\n",
      "Accuracy: 80.15%\n",
      "ROC AUC: 0.8057\n",
      "\n",
      "Top 10 most important features:\n",
      "                 Feature  Coefficient  Abs_Coefficient\n",
      "13   cat__MKT_AIRLINE_DL    -2.352220         2.352220\n",
      "57    cat__DEST_IATA_DFW     2.117383         2.117383\n",
      "27  cat__ORIGIN_IATA_DFW     1.967148         1.967148\n",
      "11   cat__MKT_AIRLINE_AS     1.226451         1.226451\n",
      "40  cat__ORIGIN_IATA_MSP    -1.184190         1.184190\n",
      "23  cat__ORIGIN_IATA_BWI    -1.168694         1.168694\n",
      "15   cat__MKT_AIRLINE_G4    -1.129553         1.129553\n",
      "8          cat__WEEK_Tue     1.092593         1.092593\n",
      "33  cat__ORIGIN_IATA_JFK    -1.064681         1.064681\n",
      "71    cat__DEST_IATA_ORD    -1.022378         1.022378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_2488\\1181692129.py:363: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./cancelled_prob_lr_models/May2021_model.joblib\n",
      "Processing of May2021.csv completed in 7.84 seconds\n",
      "\n",
      "Processing file 2/4: May2022.csv (May 2022)\n",
      "Months found in data: {5: 602950}\n",
      "Filtered to only May data: 602950 rows\n",
      "Filtered from 602950 to 210079 rows for top 30 airports\n",
      "Creating red-eye flight indicator...\n",
      "Identified 6180 red-eye flights based on departure time (0-6 AM)\n",
      "Identified 7586 red-eye flights based on arrival time (0-6 AM)\n",
      "Total identified red-eye flights: 13296 out of 210079 total flights (6.33%)\n",
      "\n",
      "Distribution of flights by departure time of day:\n",
      "  - Morning (6-12): 79757 flights (37.97%)\n",
      "  - Afternoon (12-18): 71342 flights (33.96%)\n",
      "  - Evening (18-24): 48014 flights (22.86%)\n",
      "  - Early Morning (0-6): 10966 flights (5.22%)\n",
      "Final dataset shape: (210079, 52)\n",
      "Preprocessing data...\n",
      "Overall cancellation rate: 4659/210079 (2.22%)\n",
      "Red-eye flights cancellation rate: 1.56%\n",
      "Non-red-eye flights cancellation rate: 2.26%\n",
      "Matching weather data with flights...\n",
      "Matched weather data for 0 flights (0.00%)\n",
      "Selecting features...\n",
      "Using categorical features: ['YEAR', 'WEEK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'EXTREME_WEATHER', 'IS_REDEYE']\n",
      "Using numerical features: ['DISTANCE', 'PRCP']\n",
      "Training set size: (189071, 9)\n",
      "Test set size: (21008, 9)\n",
      "Training logistic regression model...\n",
      "Model training took: 1.12 seconds\n",
      "Evaluating model...\n",
      "Accuracy: 68.24%\n",
      "ROC AUC: 0.7532\n",
      "\n",
      "Top 10 most important features:\n",
      "                 Feature  Coefficient  Abs_Coefficient\n",
      "15   cat__MKT_AIRLINE_G4    -2.346080         2.346080\n",
      "9          cat__WEEK_Wed    -1.325535         1.325535\n",
      "59    cat__DEST_IATA_EWR     1.279936         1.279936\n",
      "29  cat__ORIGIN_IATA_EWR     1.213278         1.213278\n",
      "11   cat__MKT_AIRLINE_AS     1.070665         1.070665\n",
      "36  cat__ORIGIN_IATA_LGA     1.006664         1.006664\n",
      "38  cat__ORIGIN_IATA_MDW    -1.006076         1.006076\n",
      "66    cat__DEST_IATA_LGA     0.999596         0.999596\n",
      "3          cat__WEEK_Fri     0.893741         0.893741\n",
      "7          cat__WEEK_Thu    -0.880589         0.880589\n",
      "Model saved to ./cancelled_prob_lr_models/May2022_model.joblib\n",
      "Processing of May2022.csv completed in 9.46 seconds\n",
      "\n",
      "Processing file 3/4: May2023.csv (May 2023)\n",
      "Months found in data: {5: 616630}\n",
      "Filtered to only May data: 616630 rows\n",
      "Filtered from 616630 to 220469 rows for top 30 airports\n",
      "Creating red-eye flight indicator...\n",
      "Identified 6526 red-eye flights based on departure time (0-6 AM)\n",
      "Identified 8941 red-eye flights based on arrival time (0-6 AM)\n",
      "Total identified red-eye flights: 15208 out of 220469 total flights (6.90%)\n",
      "\n",
      "Distribution of flights by departure time of day:\n",
      "  - Morning (6-12): 83273 flights (37.77%)\n",
      "  - Afternoon (12-18): 73615 flights (33.39%)\n",
      "  - Evening (18-24): 51863 flights (23.52%)\n",
      "  - Early Morning (0-6): 11718 flights (5.32%)\n",
      "Final dataset shape: (220469, 52)\n",
      "Preprocessing data...\n",
      "Overall cancellation rate: 1293/220469 (0.59%)\n",
      "Red-eye flights cancellation rate: 0.74%\n",
      "Non-red-eye flights cancellation rate: 0.57%\n",
      "Matching weather data with flights...\n",
      "Matched weather data for 0 flights (0.00%)\n",
      "Selecting features...\n",
      "Using categorical features: ['YEAR', 'WEEK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'EXTREME_WEATHER', 'IS_REDEYE']\n",
      "Using numerical features: ['DISTANCE', 'PRCP']\n",
      "Training set size: (198422, 9)\n",
      "Test set size: (22047, 9)\n",
      "Training logistic regression model...\n",
      "Model training took: 0.79 seconds\n",
      "Evaluating model...\n",
      "Accuracy: 65.28%\n",
      "ROC AUC: 0.7028\n",
      "\n",
      "Top 10 most important features:\n",
      "                 Feature  Coefficient  Abs_Coefficient\n",
      "32  cat__ORIGIN_IATA_IAH     1.065980         1.065980\n",
      "62    cat__DEST_IATA_IAH     0.976884         0.976884\n",
      "57    cat__DEST_IATA_DFW     0.902241         0.902241\n",
      "27  cat__ORIGIN_IATA_DFW     0.875253         0.875253\n",
      "56    cat__DEST_IATA_DEN     0.694581         0.694581\n",
      "24  cat__ORIGIN_IATA_CLT    -0.689698         0.689698\n",
      "8          cat__WEEK_Tue    -0.642942         0.642942\n",
      "38  cat__ORIGIN_IATA_MDW    -0.632270         0.632270\n",
      "12   cat__MKT_AIRLINE_B6     0.628826         0.628826\n",
      "41  cat__ORIGIN_IATA_ORD    -0.609822         0.609822\n",
      "Model saved to ./cancelled_prob_lr_models/May2023_model.joblib\n",
      "Processing of May2023.csv completed in 9.51 seconds\n",
      "\n",
      "Processing file 4/4: May2024.csv (May 2024)\n",
      "Months found in data: {5: 649428}\n",
      "Filtered to only May data: 649428 rows\n",
      "Filtered from 649428 to 228159 rows for top 30 airports\n",
      "Creating red-eye flight indicator...\n",
      "Identified 6247 red-eye flights based on departure time (0-6 AM)\n",
      "Identified 8321 red-eye flights based on arrival time (0-6 AM)\n",
      "Total identified red-eye flights: 14238 out of 228159 total flights (6.24%)\n",
      "\n",
      "Distribution of flights by departure time of day:\n",
      "  - Morning (6-12): 85336 flights (37.40%)\n",
      "  - Afternoon (12-18): 78253 flights (34.30%)\n",
      "  - Evening (18-24): 52714 flights (23.10%)\n",
      "  - Early Morning (0-6): 11856 flights (5.20%)\n",
      "Final dataset shape: (228159, 52)\n",
      "Preprocessing data...\n",
      "Overall cancellation rate: 2994/228159 (1.31%)\n",
      "Red-eye flights cancellation rate: 1.76%\n",
      "Non-red-eye flights cancellation rate: 1.28%\n",
      "Matching weather data with flights...\n",
      "Matched weather data for 0 flights (0.00%)\n",
      "Selecting features...\n",
      "Using categorical features: ['YEAR', 'WEEK', 'MKT_AIRLINE', 'ORIGIN_IATA', 'DEST_IATA', 'EXTREME_WEATHER', 'IS_REDEYE']\n",
      "Using numerical features: ['DISTANCE', 'PRCP']\n",
      "Training set size: (205343, 9)\n",
      "Test set size: (22816, 9)\n",
      "Training logistic regression model...\n",
      "Model training took: 1.01 seconds\n",
      "Evaluating model...\n",
      "Accuracy: 72.94%\n",
      "ROC AUC: 0.8107\n",
      "\n",
      "Top 10 most important features:\n",
      "                 Feature  Coefficient  Abs_Coefficient\n",
      "15   cat__MKT_AIRLINE_G4    -1.911891         1.911891\n",
      "57    cat__DEST_IATA_DFW     1.505319         1.505319\n",
      "27  cat__ORIGIN_IATA_DFW     1.477093         1.477093\n",
      "14   cat__MKT_AIRLINE_F9     1.378668         1.378668\n",
      "13   cat__MKT_AIRLINE_DL    -1.059453         1.059453\n",
      "62    cat__DEST_IATA_IAH     0.952544         0.952544\n",
      "32  cat__ORIGIN_IATA_IAH     0.939643         0.939643\n",
      "10   cat__MKT_AIRLINE_AA     0.902642         0.902642\n",
      "5          cat__WEEK_Sat    -0.804926         0.804926\n",
      "17   cat__MKT_AIRLINE_UA     0.618356         0.618356\n",
      "Model saved to ./cancelled_prob_lr_models/May2024_model.joblib\n",
      "Processing of May2024.csv completed in 10.38 seconds\n",
      "\n",
      "Summary of logistic regression model training:\n",
      "Successfully trained models: 4/4\n",
      "Failed models: 0/4\n",
      "Skipped files: 0/4\n",
      "\n",
      "Average metrics across all successful models:\n",
      "Accuracy: 71.65%\n",
      "ROC AUC: 0.7681\n",
      "Precision: 0.0261\n",
      "Recall: 0.7085\n",
      "\n",
      "Most common important features across all models:\n",
      "cat__DEST_IATA_DFW: Appears in 3 models (75.0%)\n",
      "cat__ORIGIN_IATA_DFW: Appears in 3 models (75.0%)\n",
      "cat__MKT_AIRLINE_DL: Appears in 2 models (50.0%)\n",
      "cat__MKT_AIRLINE_AS: Appears in 2 models (50.0%)\n",
      "cat__MKT_AIRLINE_G4: Appears in 2 models (50.0%)\n",
      "cat__ORIGIN_IATA_MSP: Appears in 1 models (25.0%)\n",
      "cat__WEEK_Wed: Appears in 1 models (25.0%)\n",
      "cat__DEST_IATA_EWR: Appears in 1 models (25.0%)\n",
      "cat__ORIGIN_IATA_EWR: Appears in 1 models (25.0%)\n",
      "cat__ORIGIN_IATA_IAH: Appears in 1 models (25.0%)\n",
      "\n",
      "Average red-eye vs non-red-eye cancellation rate comparison saved to average_redeye_comparison.png\n",
      "\n",
      "Logistic regression model training with red-eye flight detection complete!\n",
      "Full summary saved to ./cancelled_prob_lr_models/cancelled_prob_lr_summary.csv\n"
     ]
    }
   ],
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
